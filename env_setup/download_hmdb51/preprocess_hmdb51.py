#!/usr/bin/env python3
"""
Preprocess HMDB51 videos for Open-Sora v1.3 training.

Performs the following preprocessing steps:
1. Center-crop videos to 480p (640x480)
2. Resample videos to 24 fps
3. Uniformly crop to 45 frames
4. Generate CSV metadata file with video information
5. Optional: Delete original dataset to save disk space (~2-4GB)
"""

import os
import sys
import json
import argparse
import shutil
from pathlib import Path
from typing import Dict, Tuple, Optional
from tqdm import tqdm
import pandas as pd

import numpy as np
import torch
import torch.nn.functional as F
import av
from av.video.frame import VideoFrame
from av.video.stream import VideoStream


def read_captions(captions_file: Path) -> Dict[str, str]:
    """
    Read captions from the captions.txt file generated by download script.
    
    Format: <relative_path>\t<caption>
    
    Args:
        captions_file: Path to captions.txt
        
    Returns:
        Dictionary mapping video relative path to caption
    """
    captions_dict = {}
    if not captions_file.exists():
        print(f"Warning: {captions_file} does not exist. No captions will be included.")
        return captions_dict
    
    with open(captions_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split('\t', 1)
            if len(parts) == 2:
                rel_path, caption = parts
                captions_dict[rel_path] = caption
            else:
                # If no tab separator, assume the whole line is the path
                rel_path = parts[0]
                # Use directory name as caption
                caption = Path(rel_path).parent.name
                captions_dict[rel_path] = caption
    
    print(f"Loaded {len(captions_dict)} captions from {captions_file}")
    return captions_dict


def resize_crop_to_480p(frames: np.ndarray) -> np.ndarray:
    """
    Center-crop and resize video to 480p (640x480).
    
    Args:
        frames: Video frames in shape (T, H, W, C)
        
    Returns:
        Resized and center-cropped frames in shape (T, 480, 640, C)
    """
    T, H, W, C = frames.shape
    target_h, target_w = 480, 640
    target_aspect = target_w / target_h  # 640/480 = 4/3
    
    # Calculate crop dimensions to maintain 4:3 aspect ratio
    if W / H > target_aspect:
        # Video is wider than target aspect ratio
        crop_w = int(H * target_aspect)
        crop_h = H
        start_w = (W - crop_w) // 2
        start_h = 0
    else:
        # Video is taller than target aspect ratio
        crop_w = W
        crop_h = int(W / target_aspect)
        start_w = 0
        start_h = (H - crop_h) // 2
    
    # Perform center crop
    cropped = frames[:, start_h:start_h+crop_h, start_w:start_w+crop_w, :]
    
    # Resize to target dimensions
    frames_tensor = torch.from_numpy(cropped).permute(0, 3, 1, 2).float()  # TCHW
    resized = F.interpolate(
        frames_tensor,
        size=(target_h, target_w),
        mode='bilinear',
        align_corners=False
    )
    
    # Convert back to THWC format
    return resized.permute(0, 2, 3, 1).numpy().astype(np.uint8)


def resample_frames(frames: np.ndarray, old_fps: float, new_fps: float) -> np.ndarray:
    """
    Resample video frames from old_fps to new_fps using linear temporal interpolation.
    
    Args:
        frames: Video frames in shape (T, H, W, C)
        old_fps: Original frame rate
        new_fps: Target frame rate
        
    Returns:
        Resampled frames in shape (T', H, W, C)
    """
    T, H, W, C = frames.shape
    
    # Calculate new number of frames
    duration = T / old_fps
    new_T = int(round(duration * new_fps))
    
    if new_T == 0:
        return np.zeros((0, H, W, C), dtype=np.uint8)
    
    if new_T == T:
        # No resampling needed
        return frames
    
    # Create time points for resampling
    new_times = np.linspace(0, T - 1, new_T)
    
    # Interpolate temporal dimension
    resampled_frames = []
    for new_t in new_times:
        # Find nearest frames
        old_idx = int(new_t)
        alpha = new_t - old_idx
        
        if old_idx >= T - 1:
            frame = frames[-1]
        elif alpha < 1e-6:
            frame = frames[old_idx]
        else:
            # Linear interpolation between frames
            frame1 = frames[old_idx].astype(np.float32)
            frame2 = frames[min(old_idx + 1, T - 1)].astype(np.float32)
            frame = (frame1 * (1 - alpha) + frame2 * alpha).astype(np.uint8)
        
        resampled_frames.append(frame)
    
    resampled = np.stack(resampled_frames, axis=0)
    
    return resampled


def crop_to_frames(frames: np.ndarray, num_frames: int) -> Tuple[Optional[np.ndarray], Optional[int], Optional[int]]:
    """
    Uniformly crop video to exactly num_frames.
    If video is too short, return None.
    
    Args:
        frames: Video frames in shape (T, H, W, C)
        num_frames: Target number of frames
        
    Returns:
        Tuple of (cropped_frames, start_idx, end_idx) or (None, None, None) if too short
    """
    T, H, W, C = frames.shape
    
    if T < num_frames:
        return None, None, None
    
    # Random crop location
    max_start = T - num_frames
    start_idx = np.random.randint(0, max_start + 1)
    end_idx = start_idx + num_frames
    
    cropped = frames[start_idx:end_idx]
    
    return cropped, start_idx, end_idx


def preprocess_video(
    video_path: Path,
    output_dir: Path,
    captions_dict: Dict[str, str],
    base_dir: Path,
    root_dir: Path
) -> Optional[Dict]:
    """
    Preprocess a single video according to Open-Sora v1.3 requirements.
    
    Args:
        video_path: Path to input video file
        output_dir: Directory to save preprocessed video
        captions_dict: Dictionary mapping relative paths to captions
        base_dir: Base directory for relative paths
        root_dir: Root directory (hmdb51) for relative paths
        
    Returns:
        Dictionary with metadata or None if preprocessing failed
    """
    try:
        # Open video file
        container = av.open(str(video_path))
        video_stream = container.streams.video[0]
        
        # Get original video properties
        original_fps = float(video_stream.average_rate)
        width = video_stream.width
        height = video_stream.height
        
        # Read all frames
        frames = []
        for frame in container.decode(video=0):
            frames.append(frame.to_ndarray(format='rgb24'))
        container.close()
        
        if len(frames) == 0:
            print(f"Warning: No frames found in {video_path}")
            return None
        
        frames = np.stack(frames)  # T, H, W, C
        
        # Step 1: Center-crop to 480p (640x480)
        frames = resize_crop_to_480p(frames)
        
        # Step 2: Resample to 24 fps
        frames = resample_frames(frames, original_fps, 24.0)
        
        # Step 3: Crop to 45 frames (skip if too short)
        cropped_frames, start_idx, end_idx = crop_to_frames(frames, 45)
        
        if cropped_frames is None:
            print(f"Warning: {video_path.name} is too short after resampling ({len(frames)} frames < 45). Skipping.")
            return None
        
        # Save preprocessed video
        output_path = output_dir / video_path.relative_to(base_dir)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Write video using av
        output_container = av.open(str(output_path), mode='w')
        output_stream = output_container.add_stream('libx264', rate=24)
        output_stream.width = 640
        output_stream.height = 480
        output_stream.pix_fmt = 'yuv420p'
        
        for frame_array in cropped_frames:
            frame = VideoFrame.from_ndarray(frame_array, format='rgb24')
            for packet in output_stream.encode(frame):
                output_container.mux(packet)
        
        # Flush encoder
        for packet in output_stream.encode():
            output_container.mux(packet)
        
        output_container.close()
        
        # Get relative path for metadata
        rel_path = output_path.relative_to(root_dir)
        rel_path_str = str(rel_path).replace('\\', '/')
        
        # Get caption
        original_rel_path = video_path.relative_to(base_dir)
        caption = captions_dict.get(str(original_rel_path).replace('\\', '/'), str(original_rel_path.parent))
        
        # Create metadata
        metadata = {
            'path': rel_path_str,
            'num_frames': 45,
            'conditioning_frames': 32,
            'height': 480,
            'width': 640,
            'fps': 24,
            'text': caption
        }
        
        return metadata
        
    except Exception as e:
        print(f"Error processing {video_path}: {e}")
        import traceback
        traceback.print_exc()
        return None


def main(args):
    hmdb51_dir = Path(__file__).parent.absolute()
    
    # Setup paths
    input_dir = hmdb51_dir / 'hmdb51_org'
    output_dir = hmdb51_dir / 'hmdb51_processed'
    captions_file = hmdb51_dir / 'captions.txt'
    rar_file = hmdb51_dir / 'hmdb51_org.rar'
    
    print("=" * 70)
    print("HMDB51 Video Preprocessing for Open-Sora v1.3")
    print("=" * 70)
    
    # Check input directory
    if not input_dir.exists():
        print(f"Error: Input directory {input_dir} does not exist!")
        print("Please run download_hmdb51.py first.")
        sys.exit(1)
    
    # Create output directory
    output_dir.mkdir(exist_ok=True)
    print(f"Output directory: {output_dir}")
    
    # Load captions
    captions_dict = read_captions(captions_file)
    
    # Find all video files
    video_files = list(input_dir.rglob('*.avi'))
    print(f"\nFound {len(video_files)} video files")
    
    if len(video_files) == 0:
        print("No video files found!")
        sys.exit(1)
    
    # Process videos
    metadata_list = []
    skipped_count = 0
    
    print("\nProcessing videos...")
    for video_path in tqdm(video_files, desc="Preprocessing"):
        metadata = preprocess_video(video_path, output_dir, captions_dict, input_dir, hmdb51_dir)
        
        if metadata:
            metadata_list.append(metadata)
        else:
            skipped_count += 1
    
    # Save metadata CSV
    if metadata_list:
        df = pd.DataFrame(metadata_list)
        csv_path = hmdb51_dir / 'hmdb51_metadata.csv'
        df.to_csv(csv_path, index=False)
        
        print("\n" + "=" * 70)
        print("Preprocessing Complete!")
        print("=" * 70)
        print(f"Successfully processed: {len(metadata_list)} videos")
        print(f"Skipped: {skipped_count} videos (too short)")
        print(f"Metadata saved to: {csv_path}")
        print(f"Preprocessed videos saved to: {output_dir}")
        print("\nCSV Columns:")
        print("  - path: Relative path to preprocessed video")
        print("  - num_frames: Number of frames (45)")
        print("  - conditioning_frames: Conditioning frames (32)")
        print("  - height: Video height (480)")
        print("  - width: Video width (640)")
        print("  - fps: Frame rate (24)")
        print("  - text: Video caption")
        print("\nYou can now use hmdb51_metadata.csv for Open-Sora training!")
        
        # Ask user if they want to delete original dataset to save space
        print("\n" + "=" * 70)
        print("Disk Space Cleanup")
        print("=" * 70)
        
        # Calculate size of original data
        original_size = 0
        if input_dir.exists():
            for file_path in input_dir.rglob('*'):
                if file_path.is_file():
                    original_size += file_path.stat().st_size
        
        if rar_file.exists():
            original_size += rar_file.stat().st_size
        
        # Convert to human-readable format
        if original_size > 1024**3:
            size_str = f"{original_size / (1024**3):.2f} GB"
        elif original_size > 1024**2:
            size_str = f"{original_size / (1024**2):.2f} MB"
        else:
            size_str = f"{original_size / 1024:.2f} KB"
        
        print(f"\nOriginal dataset size: {size_str}")
        print("This includes:")
        if input_dir.exists():
            print(f"  - {input_dir} (extracted videos)")
        if rar_file.exists():
            print(f"  - {rar_file} (archive file)")
        print("\nTo save disk space, you can delete the original dataset.")
        print("Only preprocessed videos will remain on disk.")
        
        # Skip interactive prompt if --skip-cleanup flag is set
        if args.skip_cleanup:
            print("\nSkipping cleanup (--skip-cleanup flag set). Original dataset retained.")
            return
        
        response = input("\nDelete original dataset? (yes/no) [default: no]: ").strip().lower()
        
        if response in ['yes', 'y']:
            print("\nDeleting original dataset...")
            
            if input_dir.exists():
                shutil.rmtree(input_dir)
                print(f"✓ Deleted {input_dir}")
            
            if rar_file.exists():
                rar_file.unlink()
                print(f"✓ Deleted {rar_file}")
            
            print(f"\n✓ Freed approximately {size_str} of disk space!")
            print("Only preprocessed videos remain in: {}".format(output_dir))
        else:
            print("\nOriginal dataset retained. You can delete it manually later:")
            if input_dir.exists():
                print(f"  rm -rf {input_dir}")
            if rar_file.exists():
                print(f"  rm {rar_file}")
    else:
        print("\nError: No videos were successfully processed!")
        sys.exit(1)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Preprocess HMDB51 videos for Open-Sora v1.3')
    parser.add_argument(
        '--skip-cleanup', 
        action='store_true',
        help='Skip interactive cleanup prompt (for batch/job submissions)'
    )
    args = parser.parse_args()
    main(args)

